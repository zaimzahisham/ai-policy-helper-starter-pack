# Embedding Configuration
EMBEDDING_MODEL=local-384

# LLM Provider Configuration
# Options: stub (default, offline), openai, ollama
LLM_PROVIDER=stub

# OpenAI Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=

# Ollama Configuration (if using Ollama)
OLLAMA_HOST=http://ollama:11434

# Vector Store Configuration
# Options: qdrant (default), memory
VECTOR_STORE=qdrant

# Qdrant Collection Name
COLLECTION_NAME=policy_helper

# Chunking Configuration
CHUNK_SIZE=700
CHUNK_OVERLAP=80

# Data Directory (path to policy documents)
DATA_DIR=/app/data

# Frontend API Base URL
NEXT_PUBLIC_API_BASE=http://localhost:8000
